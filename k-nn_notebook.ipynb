{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC ML LabExercise: k - Nearest Neighbours \n",
    "Ungraded exercise, deadline Thursday 9 November, 23:59.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will implement the k-Nearest Neighbour classifier.\n",
    "\n",
    "The step-wise recipe for k-nn:\n",
    "\n",
    "(1) Handle Data: Open the dataset from CSV and split into test/train datasets.\n",
    "\n",
    "(2) Similarity: Calculate the distance between two data instances.\n",
    "\n",
    "(3) Neighbors: Locate k most similar data instances.\n",
    "\n",
    "(4) Majority vote: Get the neighbours to vote on the class of the test points.\n",
    "\n",
    "(5) Accuracy: Summarize the accuracy of predictions.\n",
    "\n",
    "\n",
    "We provide the main function that brings all the steps together and your task is to implement the missing functions.\n",
    "Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "\n",
    "\n",
    "| Sample:  | Sepal Length | Sepal Width | Petal Length | Petal Width  |\n",
    "|---|---|---|---|---|\n",
    "| train|  |  |  |  | \n",
    "| test|  |  |  |  | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In this notebook we will work with the Iris dataset again\n",
    "#First we import all the modules that you need for this exrecise\n",
    "from sklearn import datasets # to load the dataset\n",
    "from sklearn.model_selection import train_test_split #to split in train and test set\n",
    "from sklearn.model_selection import cross_val_score #BONUS\n",
    "from sklearn.metrics import classification_report, accuracy_score # for reporting\n",
    "from scipy.spatial import distance #to calculate the Euclidean distance\n",
    "from collections import Counter #to count unique occurances of items in array, for majority voting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.1  3.5  1.4  0.2]\n",
      "[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[0]\n",
    "print(X)\n",
    "print(iris.target[43:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "stats = {0 : 1, 1 : 2, 2 : 3}\n",
    "\n",
    "print(max(stats, key=stats.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing function  1) given a training set and a test instance use \n",
    "# the euclidian distance function to calculate all pairwise distances.\n",
    "# Return a list with indexes of k nearest neighbours for a given test instance.\n",
    "\n",
    "\n",
    "def get_neighbours(training_set, test_instance, k):\n",
    "    # Remember to save not only distances but also the index of the training example,\n",
    "    # so that when you want to choose k closest ones, you actually know which examples those are.\n",
    "    dneighbours = [distance.euclidean(test_instance, sample) for sample in training_set]\n",
    "    neighbours = np.argpartition(numpy.array(dneighbours), k)[:k].tolist()\n",
    "    \n",
    "\n",
    "def get_majority_vote(neighbours, training_labels):\n",
    "    count = Counter()\n",
    "    for idx in neighbours:\n",
    "        count[training_labels.target[idx]] += 1    # get class from training set & add classes in dict\n",
    "    clss = max(count, key=count.get) # return largest dictitem\n",
    "    \n",
    "    \n",
    "# setting up main executable method\n",
    "def main():\n",
    " \n",
    "    # load the data and create the training and test sets\n",
    "    iris = datasets.load_iris()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4) \n",
    "\n",
    "    # generate predictions\n",
    "    predictions = []\n",
    " \n",
    "    # let's arbitrarily set k equal to 3, see BONUS question\n",
    "    k = 3   \n",
    "    \n",
    "    # for each instance in the test set, get nearest neighbours and majority vote on predicted class\n",
    "    for x in range(len(X_test)):\n",
    "            print(x)\n",
    "            \n",
    "            #print('Classifying test instance number ' + str(x) + \":\")\n",
    "            #neighbours = get_neighbours(X_train, X_test[x], k)\n",
    "            #majority_vote = get_majority_vote(neighbours, y_train)\n",
    "            #predictions.append(majority_vote)\n",
    "            #print('Predicted label=' + str(majority_vote) + ', Actual label=' + str(y_test[x]))\n",
    " \n",
    "    # summarize performance of the classification\n",
    "    #print('\\nThe overall accuracy of the model is: ' + str(accuracy_score(y_test, predictions)) + \"\\n\")\n",
    "    \n",
    "    #BONUS: study function classification_report to find out how to produce \n",
    "    #       a detailes classification report\n",
    "    #       report = classification_report(...)\n",
    "    #       print('A detailed classification report: \\n\\n' + report)\n",
    "    \n",
    "    \n",
    "    # BONUS: in this implementation we arbitrarily chose k=3. \n",
    "    #        We could have chosen other values, which would influence accuracy. \n",
    "    #        Ideally, k would be optimized by seeing which value \n",
    "    #        produces the most accurate predictions. \n",
    "    #        Implement this using cross-validation. \n",
    "\n",
    "#main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
