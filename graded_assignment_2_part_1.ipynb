{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graded Lab Assignment 2: Evaluate classifiers (10 points)\n",
    " \n",
    "In this assignment you will optimize and compare the perfomance of a parametric (logistic regression) and non-parametric (k-nearest neighbours) classifier on the MNIST dataset.\n",
    "\n",
    "Publish your notebook (ipynb file) to your Machine Learning repository on Github ON TIME. We will check the last commit on the day of the deadline.  \n",
    "\n",
    "### Deadline Friday, November 17, 23:59.\n",
    "\n",
    "This notebook consists of three parts: design, implementation, results & analysis. \n",
    "We provide you with the design of the experiment and you have to implement it and analyse the results.\n",
    "\n",
    "### Criteria used for grading\n",
    "* Explain and analyse all results.\n",
    "* Make your notebook easy to read. When you are finished take your time to review it!\n",
    "* You do not want to repeat the same chunks of code multiply times. If your need to do so, write a function. \n",
    "* The implementation part of this assignment needs careful design before you start coding. You could start by writing pseudocode.\n",
    "* In this exercise the insights are important. Do not hide them somewhere in the comments in the implementation, but put them in the Analysis part\n",
    "* Take care that all the figures and tables are well labeled and numbered so that you can easily refer to them.\n",
    "* A plot should have a title and axes labels.\n",
    "* You may find that not everything is 100% specified in this assignment. That is correct! Like in real life you probably have to make some choices. Motivate your choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading points distribution\n",
    "\n",
    "* Implementation 5 points\n",
    "* Results and analysis 5 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to keep the order of this design and are allowed to alter it if you are confident.\n",
    "* Import all necessary modules. Try to use as much of the available functions as possible. \n",
    "* Use the provided train and test set of MNIST dataset.\n",
    "* Pre-process data eg. normalize/standardize, reformat, etc.           \n",
    "  Do whatever you think is necessary and motivate your choices.\n",
    "* (1) Train logistic regression and k-nn using default settings.\n",
    "* Use 10-fold cross validation for each classifier to optimize the performance for one parameter: \n",
    "    * consult the documentation on how cross validation works in sklearn (important functions:             cross_val_score(), GridSearchCV()).\n",
    "    * Optimize k for k-nn,\n",
    "    * for logistic regression focus on the regularization parameter,\n",
    "* (2) Train logistic regression and k-nn using optimized parameters.\n",
    "* Show performance on the cross-validation set for (1) and (2) for both classifiers: \n",
    "    * report the average cross validation error rates (alternatively, the average accuracies - it's up to you) and standard deviation,\n",
    "    * plot the average cross valildation errors (or accuracies) for different values of the parameter that you tuned. \n",
    "* Compare performance on the test set for two classifiers:\n",
    "    * produce the classification report for both classifiers, consisting of precision, recall, f1-score. Explain and analyse the results.\n",
    "    * print confusion matrix for both classifiers and compare whether they missclassify the same  classes. Explain and analyse the results.\n",
    "* Discuss your results.\n",
    "* BONUS: only continue with this part if you are confident that your implemention is complete \n",
    "    * tune more parameters of logistic regression\n",
    "    * add additional classifiers (NN, Naive Bayes, decision tree), \n",
    "    * analyse additional dataset (ex. Iris dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import classification_report, accuracy_score \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "digits = datasets.load_digits()\n",
    "X_train_mnist = reshape(digits.images[:1500],(1500,64))\n",
    "X_test_mnist = reshape(digits.images[1500:],(297,64))\n",
    "y_train_mnist = digits.target[:1500]\n",
    "y_test_mnist = digits.target[1500:]\n",
    "\n",
    "#scaling the train and test arrays\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_mnist)\n",
    "scaler.fit(X_test_mnist)\n",
    "X_train_transform = scaler.transform(X_train_mnist)\n",
    "X_test_transform = scaler.transform(X_test_mnist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy defaualt model:  0.941446300269\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression() #creating a default model where C = 5\n",
    "model_lr.fit(X_train_transform, y_train_mnist)\n",
    "#Use 10-fold crossvalidation to calculate the average accuracy\n",
    "cv_score_lr = cross_val_score(model_lr, X_train_transform, y_train_mnist, cv=10, scoring='accuracy')\n",
    "avgscore_lr = sum(cv_score_lr)/10\n",
    "print('average accuracy default model: ', avgscore_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average cross validation errors plot LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cplt = [c/8 for c in range(1,21)] #from 0.125 to 2.5 in steps of 0.125 \n",
    "\n",
    "scoreplt = []\n",
    "for c in Cplt:\n",
    "    lr = LogisticRegression(C = c)\n",
    "    scores_lr = cross_val_score(lr, X_train_transform, y_train_mnist, cv=10, scoring='accuracy')\n",
    "    scoreplt.append(sum(scores_lr)/10)\n",
    "    \n",
    "plt.plot(Cplt, scoreplt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best C seems to lie around 0.5. In order to see find the best C we iterate from around 0.375 to 0.625 in smaller chunks in order to find the value where cv_score is highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = [i/50 for i in list(range(18, 33))] # steps of 0.02 from 0.36 to 0.64\n",
    "\n",
    "cv_scores_C = dict()\n",
    "\n",
    "for c in C: \n",
    "    # For each value in C create a LR model with C = c and caalculate its accuracy through a 10-fold cross validation\n",
    "    lr = LogisticRegression(C = c)\n",
    "    scores_lr = cross_val_score(lr, X_train_transform, y_train_mnist, cv=10, scoring='accuracy')\n",
    "    cv_scores_C[c] = sum(scores_lr)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.36 to 1.0\n",
    "lists = sorted(cv_scores_C.items()) # sorted by key, return a list of tuples\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score when $0.48 < C < 0.54$ with an average accuracy of 0.94540\n",
    "We take C = $0.5$ for simplicities sake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction probability:  0.948266646885\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(X_train_transform, y_train_mnist)\n",
    "cv_score_knn = cross_val_score(model_knn, X_train_transform, y_train_mnist, cv=10, scoring='accuracy')\n",
    "avgscore_knn = sum(cv_score_knn)/10\n",
    "print('prediction probability: ', avgscore_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With cross validation, the best k =  1 with accuracy:  0.959534823035\n"
     ]
    }
   ],
   "source": [
    "# creating odd list of K for KNN\n",
    "myList = list(range(1,15))\n",
    "\n",
    "# subsetting just the odd ones to not deal with ties\n",
    "neighbors = list(filter(lambda x: x % 2 != 0, myList))\n",
    "\n",
    "# empty dict that will hold {k: cv score}\n",
    "cv_scores = dict()\n",
    "\n",
    "for k in neighbors:\n",
    "    # For each value in neigbours create a nn model with n_neighbors = k and score through a 10-fold cross validation\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_transform, y_train_mnist, cv=10, scoring='accuracy')\n",
    "    cv_scores[k] = sum(scores)/10\n",
    "    \n",
    "best_k_cv = max(cv_scores.values()) # find best score\n",
    "for key, value in cv_scores.items():\n",
    "    # find k of best score\n",
    "    if value == best_k_cv:\n",
    "        print('With cross validation, the best k = ', key, \"with accuracy: \", value)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average cross validation errors plot knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating odd list of K for KNN\n",
    "myList = list(range(1,11))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = list(filter(lambda x: x % 2 != 0, myList))\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "for k in range(1,11):\n",
    "    # For each value in neigbours create a nn model with n_neighbors = k and score through a 10-fold cross validation\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_transform, y_train_mnist, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(sum(scores)/10)\n",
    "plt.plot(myList, cv_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventhough k = 3 is close and would carry more information, since k = 1 is the best fit we will continue with that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Logistic regression with optimized C (C = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cv accuracy:  0.945400039237\n",
      "standard deviation:  0.0214456571311\n"
     ]
    }
   ],
   "source": [
    "model_lr_opt = LogisticRegression(C = 0.5)\n",
    "model_lr_opt.fit(X_train_transform, y_train_mnist)\n",
    "cv_score_lr_opt = cross_val_score(model_lr_opt, X_train_transform, y_train_mnist, cv=10, scoring='accuracy')\n",
    "avgscore_lr_opt = sum(cv_score_lr_opt)/10 # Average accuracy\n",
    "standarddev_lr_opt = std(cv_score_lr_opt) #standard deviation\n",
    "print('average cv accuracy: ', avgscore_lr_opt)\n",
    "print('standard deviation: ', standarddev_lr_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on trainset:  0.984666666667\n",
      "accuracy on testset:  0.888888888889\n",
      "---\n",
      "precision, recall, fscore and support of trainset with C = 0.5: \n",
      "(0.98467686336527849, 0.98466666666666669, 0.98465223025653814, None)\n",
      "precision, recall, fscore and support of testset with C = 0.5: \n",
      "(0.89591581095807415, 0.88888888888888884, 0.88674841370887081, None)\n"
     ]
    }
   ],
   "source": [
    "predtrain = model_lr_opt.predict(X_train_transform)\n",
    "print(\"accuracy on trainset: \", accuracy_score(predtrain, y_train_mnist))\n",
    "predtest = model_lr_opt.predict(X_test_transform)\n",
    "print(\"accuracy on testset: \", accuracy_score(predtest, y_test_mnist))\n",
    "print('---')\n",
    "print('precision, recall, fscore and support of trainset with C = 0.5: ')\n",
    "print(precision_recall_fscore_support(y_train_mnist, predtrain, average='weighted'))\n",
    "print('precision, recall, fscore and support of testset with C = 0.5: ')\n",
    "print(precision_recall_fscore_support(y_test_mnist, predtest, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 1-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average cv accuracy:  0.959534823035\n",
      "standard deviation:  0.0271404395113\n"
     ]
    }
   ],
   "source": [
    "model_1nn = KNeighborsClassifier(n_neighbors=1)\n",
    "model_1nn.fit(X_train_transform, y_train_mnist)\n",
    "cv_score_1nn = cross_val_score(model_1nn, X_train_transform, y_train_mnist, cv=10, scoring='accuracy')\n",
    "avgscore_1nn = sum(cv_score_1nn)/10\n",
    "standarddev_1nn = std(cv_score_1nn)\n",
    "print('average cv accuracy: ', avgscore_1nn)\n",
    "print('standard deviation: ', standarddev_1nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on trainset:  1.0\n",
      "accuracy on testset:  0.929292929293\n",
      "---\n",
      "precision, recall, fscore and support of trainset with k-nn k=1: \n",
      "(1.0, 1.0, 1.0, None)\n",
      "precision, recall, fscore and support of testset with k-nn where k=1: \n",
      "(0.93309180822044191, 0.92929292929292928, 0.92883458069178859, None)\n"
     ]
    }
   ],
   "source": [
    "predtrain_1nn = model_1nn.predict(X_train_transform)\n",
    "print(\"accuracy on trainset: \", accuracy_score(predtrain_1nn, y_train_mnist))\n",
    "predtest_1nn = model_1nn.predict(X_test_transform)\n",
    "print(\"accuracy on testset: \", accuracy_score(predtest_1nn, y_test_mnist))\n",
    "print('---')\n",
    "print('precision, recall, fscore and support of trainset with k-nn k=1: ')\n",
    "print(precision_recall_fscore_support(y_train_mnist, predtrain_1nn, average='weighted'))\n",
    "print('precision, recall, fscore and support of testset with k-nn where k=1: ')\n",
    "print(precision_recall_fscore_support(y_test_mnist, predtest_1nn, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Set:\n",
      "[[151   0   0   0   0   0   0   0   0   0]\n",
      " [  0 147   0   0   0   0   1   0   2   1]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0   0 151   0   1   0   0   1   0]\n",
      " [  0   0   0   0 146   0   0   1   0   1]\n",
      " [  0   0   0   0   0 149   1   0   0   2]\n",
      " [  0   1   0   0   1   0 149   0   0   0]\n",
      " [  0   0   0   0   0   0   0 148   0   1]\n",
      " [  0   2   1   3   0   1   0   0 139   0]\n",
      " [  0   0   0   0   0   0   0   0   2 147]]\n",
      "---\n",
      "1-nn Train Set\n",
      "[[151   0   0   0   0   0   0   0   0   0]\n",
      " [  0 151   0   0   0   0   0   0   0   0]\n",
      " [  0   0 150   0   0   0   0   0   0   0]\n",
      " [  0   0   0 153   0   0   0   0   0   0]\n",
      " [  0   0   0   0 148   0   0   0   0   0]\n",
      " [  0   0   0   0   0 152   0   0   0   0]\n",
      " [  0   0   0   0   0   0 151   0   0   0]\n",
      " [  0   0   0   0   0   0   0 149   0   0]\n",
      " [  0   0   0   0   0   0   0   0 146   0]\n",
      " [  0   0   0   0   0   0   0   0   0 149]]\n"
     ]
    }
   ],
   "source": [
    "confmat_lr_train= confusion_matrix(y_train_mnist, predtrain)\n",
    "print('Logistic Regression Train Set:')\n",
    "print(confmat_lr_train)\n",
    "print('---')\n",
    "print('1-nn Train Set')\n",
    "confmat_1nn_train= confusion_matrix(y_train_mnist, predtrain_1nn)\n",
    "print(confmat_1nn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Set:\n",
      "[[25  0  0  0  1  0  1  0  0  0]\n",
      " [ 0 28  0  1  0  0  0  0  2  0]\n",
      " [ 0  0 27  0  0  0  0  0  0  0]\n",
      " [ 0  2  0 18  0  3  0  3  4  0]\n",
      " [ 0  0  0  0 30  0  0  0  1  2]\n",
      " [ 0  0  0  0  0 30  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 30  0  0  0]\n",
      " [ 0  0  0  0  2  0  0 26  2  0]\n",
      " [ 0  2  0  0  0  0  0  0 26  0]\n",
      " [ 1  2  0  1  0  0  0  1  2 24]]\n",
      "---\n",
      "1-nn Test Set:\n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 31  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 24  0  0  0  3  0  0  0]\n",
      " [ 0  0  0 27  0  1  1  1  0  0]\n",
      " [ 0  0  0  0 29  0  0  1  0  3]\n",
      " [ 0  1  0  0  1 28  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 30  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 30  0  0]\n",
      " [ 0  3  0  1  0  0  0  0 23  1]\n",
      " [ 0  0  0  1  0  2  0  1  0 27]]\n"
     ]
    }
   ],
   "source": [
    "confmat_lr_test= confusion_matrix(y_test_mnist, predtest)\n",
    "print('Logistic Regression Test Set:')\n",
    "print(confmat_lr_test)\n",
    "print('---')\n",
    "confmat_1nn_test = confusion_matrix(y_test_mnist, predtest_1nn)\n",
    "print('1-nn Test Set:')\n",
    "print(confmat_1nn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and analysis of the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression\n",
    "To create a Logistic regression model that fits our data, we use Scikit's build in *LinearRegression()* function.\n",
    "We fit this standard model on our data, and calculate the accuracy.\n",
    "Where the *average accuracy default model* = **0.94145**\n",
    "\n",
    "In order to improve this we C by plotting the (cross validated) accuracy of a multiple of different Cs and finding the maximum.\n",
    "In our data set it appeared to be when $0.48 < C < 0.54$ where the accuracy of our model was **0.94540**. Eventhough it is a small improvement, it is the best we can do.\n",
    "\n",
    "##### K-Nearest Neighbours\n",
    "To create a K-nearest neighbour model that fits our data, we use Scikit's build in *KNeighborsClassifier()* function.\n",
    "We fit this standard model (k = 5) on our data, and calculate the accuracy.\n",
    "Where the *average accuracy default model* = **0.94827**\n",
    "\n",
    "While already better than the Logistic regression, we have to look whether $k = 5$ is the best model we can create.\n",
    "To figure this out we plot for different Ks and find that $k = 1$ gives us an acuracy of **0.95953**\n",
    "\n",
    "##### Training the models using our optimized parameters\n",
    "After training our two models we can compare their performance  using scikit's: *precision_recall_fscore_support(yfound, ytrue, average = weighted)*. This formula returns the following values:\n",
    "\n",
    "| set | precision | recall | f1 score |\n",
    "|-----|-----------|--------|--------|\n",
    "|LR Train| 0.984677 | 0.984667 | 0.98465 |\n",
    "|1-NN Train | 1.0 | 1.0 | 1.0|\n",
    "|---|---|---|---|\n",
    "|LR Test | 0.895916 | 0.888889 | 0.88675 |\n",
    "|1-NN Test | 0.933092 | 0.929293 | 0.928835|\n",
    "\n",
    "Note: Since 1-NN even takes the outliers into account during training 1-NN's training f1 score is perfect.\n",
    "\n",
    "As seen during the training 1-Nearest Neighbour is more acurate than logistic regression when C = 0.5\n",
    "\n",
    "When looking at the Confusion matrices, those als seem to differ drastically. This is most likely because LR is most likely misclassifies by underfitting. While 1-NN most likely misclassifies due to an outlier in the training set influencing the classification of the test set (as may be the case where 2 gets misclassified *three* times as a 6, same for 8 and 1).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
